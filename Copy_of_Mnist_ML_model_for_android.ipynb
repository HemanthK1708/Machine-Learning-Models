{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Mnist ML model for android",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemanthK1708/Machine-Learning-Models/blob/main/Copy_of_Mnist_ML_model_for_android.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2RPZQF05ngq"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEig-M385xKS"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXyJkL4WnqyS"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXX8WpQI5U6_"
      },
      "source": [
        "We start by importing TensorFlow and other supporting libraries that are used for data processing and visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS_mq4yAlXHZ"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0WlLrJcnwWp"
      },
      "source": [
        "## Download and explore the MNIST dataset\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images of handwritten digits. We will use the dataset to train our digit classification model.\n",
        "\n",
        "Each image in the MNIST dataset is a 28x28 grayscale image containing a digit from 0 to 9, and a label identifying which digit is in the image.\n",
        "![MNIST sample](https://github.com/khanhlvg/DigitClassifier/raw/master/images/mnist.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5REuMrblewK"
      },
      "source": [
        "# Keras provides a handy API to download the MNIST dataset, and split them into\n",
        "# \"train\" dataset and \"test\" dataset.\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REY5lDDylpFh"
      },
      "source": [
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "print('Pixels are normalized')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAOE84IplyWR"
      },
      "source": [
        "# Show the first 25 images in the training dataset.\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i], cmap=plt.cm.gray)\n",
        "  plt.xlabel(train_labels[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v-Wp3TxpLX6"
      },
      "source": [
        "## Train a TensorFlow model to classify digit images\n",
        "\n",
        "Next, we use Keras API to build a TensorFlow model and train it on the MNIST \"train\" dataset. After training, our model will be able to classify the digit images.\n",
        "\n",
        "Our model takes **a 28px x 28px grayscale image** as an input, and outputs **a float array of length 10** representing the probability of the image being a digit from 0 to 9.\n",
        "\n",
        "Here we use a simple convolutional neural network, which is a common technique in computer vision. We will not go into details about model architecture in this codelab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IihaBPi8a9ho"
      },
      "source": [
        "model = tf.keras.models.Sequential(\r\n",
        "    [tf.keras.layers.Flatten(input_shape=(28,28)),\r\n",
        "     tf.keras.layers.Dense(128,activation='relu'),\r\n",
        "     tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "     ]\r\n",
        ")\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer = 'adam', \r\n",
        "    loss = 'sparse_categorical_crossentropy',\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWgBGmaplzcp"
      },
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Define how to train the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFHKkb7gcJei"
      },
      "source": [
        "Let's take a closer look at our model structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7V6-UQqcuK-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n16JkSyNc5cf"
      },
      "source": [
        "There is an extra dimension with **None** shape in every layer in our model, which is called the **batch dimension**. In machine learning, we usually process data in batches to improve throughput, so TensorFlow automatically add the dimension for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJI8nqFWmMwC"
      },
      "source": [
        "# Evaluate the model using all images in the test dataset.\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-qv9-9_cUb7"
      },
      "source": [
        "Although our model is relatively simple, we were able to achieve good accuracy around 98% on new images that the model has never seen before. Let's visualize the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdlXEyUImeXC"
      },
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Predict the labels of digit images in our test dataset.\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# As the model output 10 float representing the probability of the input image\n",
        "# being a digit from 0 to 9, we need to find the largest probability value\n",
        "# to find out which digit the model predicts to be most likely in the image.\n",
        "prediction_digits = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Then plot 100 random test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(100):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  image_index = random.randint(0, len(prediction_digits))\n",
        "  plt.imshow(test_images[image_index], cmap=plt.cm.gray)\n",
        "  ax.xaxis.label.set_color(get_label_color(prediction_digits[image_index],\\\n",
        "                                           test_labels[image_index]))\n",
        "  plt.xlabel('Predicted: %d' % prediction_digits[image_index])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWROBI4iv9fY"
      },
      "source": [
        "## Convert the Keras model to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV99Izwykb-J"
      },
      "source": [
        "Now as we have trained the digit classifer model, we will convert it to TensorFlow Lite format for mobile deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fXStjR4mzkR"
      },
      "source": [
        "# Convert Keras model to TF Lite format.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_float_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_float_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfer6hI8ljEh"
      },
      "source": [
        "As we will deploy our model to a mobile device, we want our model to be as small and as fast as possible. **Quantization** is a common technique often used in on-device machine learning to shrink ML models. Here we will use 8-bit number to approximate our 32-bit weights, which in turn shrinks the model size by a factor of 4.\n",
        "\n",
        "See [TensorFlow documentation](https://www.tensorflow.org/lite/performance/post_training_quantization) to learn more about other quantization techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhY86SRTmtGC"
      },
      "source": [
        "# Re-convert the model to TF Lite using quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "quantized_model_size = len(tflite_quantized_model) / 1024\n",
        "print('Quantized model size = %dKBs,' % quantized_model_size)\n",
        "print('which is about %d%% of the float model size.'\\\n",
        "      % (quantized_model_size * 100 / float_model_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItyEwAdCCVw6"
      },
      "source": [
        "## Download the TensorFlow Lite model\n",
        "\n",
        "Let's get our model and integrate it into an Android app.\n",
        "\n",
        "If you see an error when downloading mnist.tflite from Colab, try running this cell again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Z5yLxrwbpI"
      },
      "source": [
        "# Save the quantized model to file to the Downloads directory\n",
        "f = open('mnist.tflite', \"wb\")\n",
        "f.write(tflite_quantized_model)\n",
        "f.close()\n",
        "\n",
        "# Download the digit classification model\n",
        "from google.colab import files\n",
        "files.download('mnist.tflite')\n",
        "\n",
        "print('`mnist.tflite` has been downloaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snMBJQIBttZu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}